# Autoencoders
Despite its somewhat initially-sounding cryptic name, autoencoders are a fairly basic machine learning model. Autoencoders (AE) are a family of neural networks for which the input is the same as the output. They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.

## Why Autoencoders?
Despite the fact, the practical applications of autoencoders were pretty rare some time back, today data denoising and dimensionality reduction for data visualization are considered as two main interesting practical applications of autoencoders. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.

[![](https://cdn-images-1.medium.com/max/1600/1*TOJD69Y8dZsKFEW-21xUPg.png)](https://cdn-images-1.medium.com/max/1600/1*TOJD69Y8dZsKFEW-21xUPg.png)

An autoencoder is an artificial neural network used for unsupervised learning of efficient codings. In the modern era, autoencoders have become an emerging field of research in numerous aspects such as in anomaly detection. In this post, it was expected to provide a basic understanding on the aspects of what, why and how of autoencoders.

When autoencoder is trained, we can use it to remove the noises added to images we have never seen!

![](https://cdn-images-1.medium.com/max/1600/1*9CiPof4rcAbkSQlxiIKeaA.png)
